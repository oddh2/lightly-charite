{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightly\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "import json\n",
    "import os\n",
    "from PIL import Image\n",
    "import sklearn\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils\n",
    "\n",
    "            \n",
    "def make_split(**kwargs):\n",
    "    test_size = kwargs.get('test_size')\n",
    "    labeled_path = kwargs.get('labeled_path')\n",
    "    train_path = kwargs.get('train_path')\n",
    "    test_path = kwargs.get('test_path')\n",
    "    \n",
    "    train_path.mkdir(parents=True, exist_ok=True)\n",
    "    test_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=test_size)\n",
    "\n",
    "    img_paths = []\n",
    "    labels = []\n",
    "    for label in labeled_path.iterdir():\n",
    "        for img in labeled_path.joinpath(label).iterdir():\n",
    "            img_paths.append(img)\n",
    "            labels.append(label)\n",
    "\n",
    "    idx_train, idx_test = next(sss.split(img_paths,labels))\n",
    "\n",
    "    train_imgs = [img_paths[i] for i in idx_train]\n",
    "    train_labels = [labels[i] for i in idx_train]\n",
    "\n",
    "    test_imgs = [img_paths[i] for i in idx_test]\n",
    "    test_labels = [labels[i] for i in idx_test]\n",
    "    \n",
    "    for img,label in zip(train_imgs,train_labels):        \n",
    "        dest_cat_path = train_path.joinpath(label.name)\n",
    "        dest_cat_path.mkdir(parents=True, exist_ok=True)\n",
    "        copyfile(img,dest_cat_path.joinpath(img.name))\n",
    "        \n",
    "    for img,label in zip(test_imgs,test_labels):        \n",
    "        dest_cat_path = test_path.joinpath(label.name)\n",
    "        dest_cat_path.mkdir(parents=True, exist_ok=True)\n",
    "        copyfile(img,dest_cat_path.joinpath(img.name))\n",
    "            \n",
    "\n",
    "# class UnlabeledDataset(torch.utils.data.Dataset):\n",
    "#     def __init__(self, main_dir, transform):\n",
    "#         self.main_dir = main_dir\n",
    "#         self.transform = transform\n",
    "#         self.all_imgs = os.listdir(main_dir)\n",
    "        \n",
    "#     def __len__(self):\n",
    "#         return len(self.all_imgs)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         img_loc = os.path.join(self.main_dir, self.all_imgs[idx])\n",
    "#         image = Image.open(img_loc).convert(\"RGB\")\n",
    "#         tensor_image = self.transform(image)\n",
    "#         return tensor_image\n",
    "    \n",
    "def class_distribution(dataset,class_index_dict):\n",
    "    count_dict = {}\n",
    "    for img,label in dataset:\n",
    "        if class_index_dict[label] not in count_dict:\n",
    "            count_dict.update({class_index_dict[label]:0})\n",
    "        else:\n",
    "            count_dict[class_index_dict[label]] += 1\n",
    "            \n",
    "    return count_dict\n",
    "    \n",
    "def sample_dataset(dataset,sample):\n",
    "    sample_idx = np.random.randint(len(unlabeled_dataset),size = int(sample*len(unlabeled_dataset)))\n",
    "    return torch.utils.data.Subset(dataset, sample_idx)\n",
    "    \n",
    "def load_simcrl(simclr_results_path,n_categories,model_size = 18):\n",
    "    \n",
    "    #load config\n",
    "    conf_path = simclr_results_path.joinpath('conf.json')\n",
    "    with open(conf_path,'r') as f:\n",
    "        conf = json.load(f)\n",
    "\n",
    "    #load model\n",
    "    model_path = simclr_results_path.joinpath('checkpoint.pth')\n",
    "\n",
    "    num_ftrs = conf['num_ftrs']\n",
    "    \n",
    "    model_name = conf['model_name']\n",
    "\n",
    "    resnet = lightly.models.ResNetGenerator('resnet-'+str(model_size))\n",
    "    last_conv_channels = list(resnet.children())[-1].in_features\n",
    "    backbone = nn.Sequential(\n",
    "        *list(resnet.children())[:-1],\n",
    "        nn.Conv2d(last_conv_channels, num_ftrs, 1),\n",
    "        nn.AdaptiveAvgPool2d(1)\n",
    "    )\n",
    "\n",
    "    if model_name == 'simclr':\n",
    "        model = lightly.models.SimCLR(backbone, num_ftrs=num_ftrs)\n",
    "    elif model_name == 'moco':\n",
    "        model = lightly.models.MoCo(backbone, num_ftrs=num_ftrs, m=0.99, batch_shuffle=True)\n",
    "        \n",
    "\n",
    "    encoder = lightly.embedding.SelfSupervisedEmbedding(\n",
    "        model,\n",
    "        None,\n",
    "        None,\n",
    "        None\n",
    "    )\n",
    "\n",
    "    encoder.model.load_state_dict(torch.load(model_path))\n",
    "    teacher = Teacher(encoder.model,num_ftrs,n_categories).to(device)\n",
    "    return teacher\n",
    "    \n",
    "    \n",
    "def evaluate(model,testloader,loss_function):\n",
    "  val_loss = 0\n",
    "  total = 0\n",
    "  correct = 0\n",
    "  ground_truth_list = []\n",
    "  predictions_list =  []\n",
    "  for image,label in testloader:\n",
    "      image, label = image.to(device), label.to(device)\n",
    "      outputs = model(image)\n",
    "      probabilities, predicted = torch.max(outputs.data, 1)\n",
    "      val_loss += loss_function(outputs, label.long()).item()\n",
    "      total += label.size(0)\n",
    "      correct += (predicted == label).sum().item()\n",
    "      ground_truth_list += list(label.cpu())\n",
    "      predictions_list += list(predicted.cpu())\n",
    "\n",
    "  acc = sklearn.metrics.accuracy_score(ground_truth_list,predictions_list)\n",
    "  f1 = sklearn.metrics.f1_score(ground_truth_list,predictions_list,average = 'macro')\n",
    "  precision = sklearn.metrics.precision_score(ground_truth_list,predictions_list,average = 'macro')\n",
    "  recall = sklearn.metrics.recall_score(ground_truth_list,predictions_list,average = 'macro')\n",
    "  print(f'acc:{acc:.3f} f1:{f1:.3f} precision:{precision:.3f} recall:{recall:.3f}')\n",
    "\n",
    "  metrics_dict = {'val_loss':val_loss,'acc':acc,'f1':f1,'precision':precision,'recall':recall}\n",
    "\n",
    "  return metrics_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big-self supervised models are strong semi-supervised dentists\n",
    "\n",
    "\n",
    "Inspired by [this paper](https://arxiv.org/pdf/2006.10029.pdf)\n",
    "\n",
    "\n",
    "We have a small subset of labeled data $L$ and a large pool of unlabeled data $U$. The goal is to make the most out of $U$ for training a classifier for solving the task on $L$.\n",
    "\n",
    "The procedure has three steps: \n",
    "\n",
    "* Pretrain a big SimCLR model on $U$\n",
    "* Fine-tune on $L$\n",
    "* Use the resulting model as a teacher for a smaller model, which is trained on the predictions of the teacher model on $U$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will split $L$ into a training and testing set using stratified sampling for getting splits with the same proportions of labels. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results path\n",
    "results_path = Path('/projects/self_supervised/results/apical_distillation')\n",
    "results_path.mkdir(parents=True, exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data \n",
    "\n",
    "sample_unlabeled = 1.0\n",
    "\n",
    "data_path = Path('/projects/self_supervised/data/apical_lesion/full_dataset')\n",
    "unlabeled_path = Path('/projects/self_supervised/data/apical_lesion/apical_U')\n",
    "labeled_path = Path('/projects/self_supervised/data/apical_lesion/apical_L')\n",
    "train_path = Path('/projects/self_supervised/data/apical_lesion/apical_train')\n",
    "test_path = Path('/projects/self_supervised/data/apical_lesion/apical_test')  \n",
    "\n",
    "# #not required if you already splitted the data\n",
    "\n",
    "\n",
    "# make_split(\n",
    "#     labeled_path = data_path,\n",
    "#     train_path = unlabeled_path,\n",
    "#     test_path = labeled_path,\n",
    "#     test_size = 0.01\n",
    "# ) \n",
    "\n",
    "\n",
    "# make_split(\n",
    "#     labeled_path = labeled_path,\n",
    "#     train_path = train_path,\n",
    "#     test_path = test_path,\n",
    "#     test_size = 0.5\n",
    "# )  \n",
    "\n",
    "\n",
    "input_size = 128\n",
    "batch_size = 16\n",
    "num_workers = 2\n",
    "\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((input_size, input_size)),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(360),\n",
    "    transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(\n",
    "    mean=lightly.data.collate.imagenet_normalize['mean'],\n",
    "    std=lightly.data.collate.imagenet_normalize['std'],\n",
    "    )\n",
    "])\n",
    "\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((input_size, input_size)),\n",
    "    transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(\n",
    "    mean=lightly.data.collate.imagenet_normalize['mean'],\n",
    "    std=lightly.data.collate.imagenet_normalize['std'],\n",
    "    )\n",
    "])\n",
    "\n",
    "\n",
    "trainset = datasets.ImageFolder(root=train_path, transform=train_transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=True, \n",
    "    num_workers=num_workers,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "testset = datasets.ImageFolder(root=test_path, transform=test_transform)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=True, \n",
    "    num_workers=num_workers,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "class_index_dict = {v:k for k,v in testset.class_to_idx.items()}\n",
    "\n",
    "unlabeled_dataset = datasets.ImageFolder(root=unlabeled_path, transform=train_transform)\n",
    "unlabeled_dataset = sample_dataset(unlabeled_dataset,sample_unlabeled)\n",
    "unlabeledloader = torch.utils.data.DataLoader(\n",
    "    unlabeled_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True, \n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 54\n",
      "testing 55\n",
      "unlabeled 10768\n"
     ]
    }
   ],
   "source": [
    "print('training',len(trainset))\n",
    "#print('training',class_distribution(trainset,class_index_dict))\n",
    "print('testing',len(testset))\n",
    "#print('testing',class_distribution(testset,class_index_dict))\n",
    "print('unlabeled',len(unlabeled_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla student model (resnet18)\n",
    "\n",
    "We train on $L$ a resnet18 as a baseline.\n",
    "\n",
    "We define the softmax-like function $P(y|x_{i})=\\frac{exp(f(x_{i})[y]/\\tau}{\\sum_{y'} exp(f(x_{i})[y']/\\tau}$, where $\\tau$ is a temperature parameter and $f$ the model. \n",
    "\n",
    "We will use cross-entropy defined as $-\\sum_{(x_{i},y_{i})} \\left[ log P(y_{i}|x_{i})\\right]$ as the loss function for training on $L$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Student(nn.Module):\n",
    "    def __init__(self,output_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.net = models.resnet18(pretrained=True)\n",
    "        self.net.fc = nn.Linear(self.net.fc.in_features, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        return out\n",
    "    \n",
    "def P(x,tau = 1.0):\n",
    "  return torch.exp(x/tau)/(torch.exp(x/tau).sum())\n",
    "\n",
    "class CrossEntropyLoss(torch.nn.Module):\n",
    "\n",
    "    def __init__(self,n_categories):\n",
    "        super(CrossEntropyLoss,self).__init__()\n",
    "        self.n_classes = n_categories\n",
    "\n",
    "    def forward(self, prediction, label):\n",
    "      label = torch.nn.functional.one_hot(label,num_classes=n_categories)\n",
    "      loss = -label*torch.log(P(prediction))\n",
    "      return loss.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "n_categories = len([cat for cat in labeled_path.iterdir()])\n",
    "crossent_loss = CrossEntropyLoss(n_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the student model on L+U\n",
    "\n",
    "def FolderDataset(data_path):\n",
    "    img_path_list = []\n",
    "    label_list = []\n",
    "    for label in data_path.iterdir():\n",
    "        for img in data_path.joinpath(label).iterdir():\n",
    "            label_list.append(label.name)\n",
    "            img_path_list.append(img)\n",
    "            \n",
    "    return np.array(img_path_list), np.array(label_list)\n",
    "    \n",
    "\n",
    "class FullDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, imgs_path,labels, transform):\n",
    "   \n",
    "        self.imgs_path = imgs_path\n",
    "        self.labels = labels                \n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.labels.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_loc = self.imgs_path[idx]\n",
    "        image = Image.open(img_loc).convert(\"RGB\")\n",
    "        tensor_image = self.transform(image)\n",
    "        label = torch.tensor(self.labels[idx])\n",
    "        return tensor_image,label\n",
    "    \n",
    "    \n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "train_imgs,train_labels = FolderDataset(train_path) \n",
    "U_imgs,U_labels = FolderDataset(unlabeled_path) \n",
    "\n",
    "\n",
    "imgs = np.concatenate((train_imgs,U_imgs))\n",
    "labels = np.concatenate((train_labels,U_labels))\n",
    "labels = le.fit_transform(labels)\n",
    "\n",
    "full_dataset = FullDataset(imgs,labels,train_transform)\n",
    "\n",
    "full_dataloader = torch.utils.data.DataLoader(\n",
    "    full_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True, \n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:0.979 f1:0.967 precision:0.950 recall:0.987\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-8493093cbce3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mbest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e9\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfull_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m       \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/sort_env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/sort_env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1069\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/sort_env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/sort_env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    870\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 872\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    873\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/sort_env/lib/python3.8/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/sort_env/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/sort_env/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/sort_env/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/sort_env/lib/python3.8/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "student = Student(n_categories).to(device)\n",
    "optimizer = optim.Adam(student.parameters(), lr=0.0001)\n",
    "\n",
    "patience = 3\n",
    "count = 0\n",
    "best_loss = 1e9\n",
    "for epoch in range(40):\n",
    "  for image,label in full_dataloader:\n",
    "      image, label = image.to(device), label.to(device)\n",
    "      optimizer.zero_grad()\n",
    "      loss = crossent_loss(student(image), label)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "        \n",
    "  metrics_dict = evaluate(student,testloader,crossent_loss)\n",
    "  val_loss = metrics_dict['val_loss']\n",
    "  if val_loss < best_loss:\n",
    "        #torch.save(student.state_dict(),results_path.joinpath('student.pth'))\n",
    "        best_loss = val_loss\n",
    "        best_metrics = metrics_dict\n",
    "        \n",
    "        count = 0\n",
    "  else:\n",
    "    count += 1\n",
    "  if count > patience:\n",
    "    break\n",
    "        \n",
    "        \n",
    "print('\\nBest metrics:')\n",
    "acc = best_metrics['acc']\n",
    "f1 = best_metrics['f1']\n",
    "recall = best_metrics['recall']\n",
    "precision = best_metrics['precision']\n",
    "print(f'acc:{acc:.3f} f1:{f1:.3f} precision:{precision:.3f} recall:{recall:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#train the student model on L\n",
    "\n",
    "student = Student(n_categories).to(device)\n",
    "optimizer = optim.Adam(student.parameters(), lr=0.0001)\n",
    "\n",
    "patience = 3\n",
    "count = 0\n",
    "best_loss = 1e9\n",
    "for epoch in range(40):\n",
    "  for image,label in trainloader:\n",
    "      image, label = image.to(device), label.to(device)\n",
    "      optimizer.zero_grad()\n",
    "      loss = crossent_loss(student(image), label)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "        \n",
    "  metrics_dict = evaluate(student,testloader,crossent_loss)\n",
    "  val_loss = metrics_dict['val_loss']\n",
    "  if val_loss < best_loss:\n",
    "        torch.save(student.state_dict(),results_path.joinpath('student.pth'))\n",
    "        best_loss = val_loss\n",
    "        best_metrics = metrics_dict\n",
    "        \n",
    "        count = 0\n",
    "  else:\n",
    "    count += 1\n",
    "  if count > patience:\n",
    "    break\n",
    "        \n",
    "        \n",
    "print('\\nBest metrics:')\n",
    "acc = best_metrics['acc']\n",
    "f1 = best_metrics['f1']\n",
    "recall = best_metrics['recall']\n",
    "precision = best_metrics['precision']\n",
    "print(f'acc:{acc:.3f} f1:{f1:.3f} precision:{precision:.3f} recall:{recall:.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big teacher (SimCLR)\n",
    "\n",
    "\n",
    "We fine-tune on $L$ a SimCLR model with backbone resnet50 pretrained on $U$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Teacher(nn.Module):\n",
    "    def __init__(self, model,num_ftrs,output_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.freeze = False\n",
    "        self.net = model\n",
    "        self.fc1 = nn.Linear(num_ftrs, 256)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(256, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if self.freeze:\n",
    "            with torch.no_grad():\n",
    "                y_hat = self.net.backbone(x).squeeze()\n",
    "                y_hat = self.fc1(y_hat)\n",
    "                y_hat = self.relu(y_hat)\n",
    "                y_hat = self.fc2(y_hat)\n",
    "                return y_hat\n",
    "        else:\n",
    "            y_hat = self.net.backbone(x).squeeze()\n",
    "            y_hat = self.fc1(y_hat)\n",
    "            y_hat = self.relu(y_hat)\n",
    "            y_hat = self.fc2(y_hat)\n",
    "            return y_hat\n",
    "            \n",
    "    def freeze_weights(self):\n",
    "      for p in self.net.parameters():\n",
    "          p.requires_grad = False\n",
    "      self.freeze = True\n",
    "      return self\n",
    "\n",
    "    def unfreeze_weights(self):\n",
    "      for p in self.net.parameters():\n",
    "          p.requires_grad = True\n",
    "      self.freeze = False\n",
    "      return self\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:0.505 f1:0.490 precision:0.518 recall:0.521\n",
      "acc:0.542 f1:0.525 precision:0.546 recall:0.554\n",
      "acc:0.536 f1:0.514 precision:0.530 recall:0.536\n",
      "acc:0.536 f1:0.514 precision:0.532 recall:0.539\n",
      "acc:0.542 f1:0.519 precision:0.533 recall:0.540\n",
      "acc:0.568 f1:0.526 precision:0.530 recall:0.534\n",
      "acc:0.594 f1:0.546 precision:0.547 recall:0.552\n",
      "acc:0.547 f1:0.488 precision:0.491 recall:0.490\n",
      "acc:0.594 f1:0.535 precision:0.535 recall:0.538\n",
      "acc:0.625 f1:0.555 precision:0.555 recall:0.555\n",
      "acc:0.656 f1:0.584 precision:0.586 recall:0.583\n",
      "acc:0.630 f1:0.535 precision:0.538 recall:0.534\n",
      "acc:0.625 f1:0.500 precision:0.509 recall:0.506\n",
      "acc:0.615 f1:0.506 precision:0.510 recall:0.509\n",
      "acc:0.641 f1:0.517 precision:0.531 recall:0.523\n",
      "acc:0.646 f1:0.521 precision:0.534 recall:0.525\n",
      "acc:0.651 f1:0.518 precision:0.534 recall:0.524\n",
      "acc:0.625 f1:0.469 precision:0.479 recall:0.487\n",
      "acc:0.688 f1:0.535 precision:0.582 recall:0.545\n",
      "acc:0.651 f1:0.485 precision:0.510 recall:0.506\n",
      "acc:0.615 f1:0.455 precision:0.459 recall:0.475\n",
      "acc:0.677 f1:0.536 precision:0.569 recall:0.542\n",
      "acc:0.677 f1:0.536 precision:0.574 recall:0.544\n",
      "acc:0.677 f1:0.519 precision:0.559 recall:0.532\n",
      "acc:0.667 f1:0.495 precision:0.535 recall:0.517\n",
      "acc:0.651 f1:0.510 precision:0.531 recall:0.520\n",
      "acc:0.682 f1:0.505 precision:0.566 recall:0.528\n",
      "acc:0.672 f1:0.488 precision:0.537 recall:0.516\n",
      "acc:0.703 f1:0.569 precision:0.619 recall:0.571\n",
      "acc:0.656 f1:0.497 precision:0.521 recall:0.512\n",
      "acc:0.682 f1:0.539 precision:0.583 recall:0.547\n",
      "acc:0.688 f1:0.526 precision:0.586 recall:0.541\n",
      "acc:0.661 f1:0.482 precision:0.512 recall:0.506\n",
      "\n",
      "Best metrics:\n",
      "acc:0.703 f1:0.569 precision:0.619 recall:0.571\n"
     ]
    }
   ],
   "source": [
    "#finetune simclr\n",
    "simclr_results_path = Path('/projects/self_supervised/results/bitewings_caries_moco_50')\n",
    "\n",
    "teacher = load_simcrl(simclr_results_path,n_categories,model_size = 50)\n",
    "optimizer = optim.Adam(teacher.parameters(), lr=0.000005)\n",
    "\n",
    "patience = 3\n",
    "count = 0\n",
    "best_loss = 1e9\n",
    "for epoch in range(40):\n",
    "  for image,label in trainloader:\n",
    "      image, label = image.to(device), label.to(device)\n",
    "      optimizer.zero_grad()\n",
    "      loss = crossent_loss(teacher(image), label.long())\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "  metrics_dict = evaluate(teacher,testloader,crossent_loss)\n",
    "  val_loss = metrics_dict['val_loss']\n",
    "  if val_loss < best_loss:\n",
    "        torch.save(teacher.state_dict(),results_path.joinpath('teacher.pth'))\n",
    "        best_loss = val_loss\n",
    "        best_metrics = metrics_dict\n",
    "        count = 0\n",
    "        \n",
    "  else:\n",
    "    count += 1\n",
    "  if count > patience:\n",
    "    break\n",
    "\n",
    "print('\\nBest metrics:')\n",
    "acc = best_metrics['acc']\n",
    "f1 = best_metrics['f1']\n",
    "recall = best_metrics['recall']\n",
    "precision = best_metrics['precision']\n",
    "print(f'acc:{acc:.3f} f1:{f1:.3f} precision:{precision:.3f} recall:{recall:.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model distillation\n",
    "\n",
    "The fine-tuned model often yields better performance than the vanilla model. Now that we used $L$ for finetuning the teacher model, we can use $U$ again for transfering the knowledge from the teacher to the student\n",
    "\n",
    "The procedure is as follows:\n",
    "* sample data from $U$\n",
    "* predict with the teacher\n",
    "* use the labels as targets for training the student\n",
    "\n",
    "This algorithm is expected to yield an even better model. Notice that the resulting model would be a resnet18 with even better performance than a resnet50 pretrained on $U$ and fine-tuned on $L$.\n",
    "\n",
    "We will use a distillation loss, which takes the output probabilities of the teacher model as the target for the student model.\n",
    "\n",
    "$$ -\\sum_{x_{i}} \\left[ \\sum_{y} P^{T}(y|x_{i};\\tau) log P^{S}(y|x_{i};\\tau) \\right] $$\n",
    "\n",
    "With this loss function the student doesn't only see the one-vs-zero encoding used in supervised learning, but a probability distribution as a target. This could help the student model to learn nuances of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistilLoss(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(DistilLoss,self).__init__()\n",
    "\n",
    "    def forward(self, t_output, s_output):\n",
    "      loss = -P(t_output)*torch.log(P(s_output))\n",
    "      return loss.sum().sum()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:0.693 f1:0.425 precision:0.516 recall:0.501\n",
      "acc:0.620 f1:0.563 precision:0.562 recall:0.566\n",
      "acc:0.651 f1:0.476 precision:0.497 recall:0.498\n",
      "acc:0.688 f1:0.407 precision:0.349 recall:0.489\n",
      "acc:0.677 f1:0.458 precision:0.517 recall:0.505\n",
      "acc:0.656 f1:0.410 precision:0.393 recall:0.475\n",
      "acc:0.661 f1:0.438 precision:0.462 recall:0.489\n",
      "acc:0.667 f1:0.415 precision:0.408 recall:0.483\n",
      "acc:0.703 f1:0.429 precision:0.851 recall:0.509\n",
      "acc:0.615 f1:0.500 precision:0.505 recall:0.504\n",
      "acc:0.698 f1:0.427 precision:0.600 recall:0.505\n",
      "acc:0.604 f1:0.567 precision:0.570 recall:0.580\n",
      "acc:0.698 f1:0.411 precision:0.349 recall:0.500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jose/miniconda3/envs/sort_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:0.521 f1:0.517 precision:0.570 recall:0.578\n",
      "acc:0.698 f1:0.411 precision:0.349 recall:0.500\n",
      "\n",
      "Best metrics:\n",
      "acc:0.703 f1:0.429 precision:0.851 recall:0.509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jose/miniconda3/envs/sort_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#init student\n",
    "student = Student(n_categories).to(device)\n",
    "#student.load_state_dict(torch.load(results_path.joinpath('student.pth')))\n",
    "\n",
    "#load teacher checkpoint\n",
    "teacher = load_simcrl(simclr_results_path,n_categories,model_size = 50)\n",
    "teacher.load_state_dict(torch.load(results_path.joinpath('teacher.pth')))\n",
    "teacher = teacher.freeze_weights()\n",
    "teacher.eval()\n",
    "\n",
    "distill_loss = DistilLoss()\n",
    "optimizer = optim.Adam(student.parameters(), lr=0.00001)\n",
    "\n",
    "patience = 5\n",
    "count = 0\n",
    "best_loss = 1e9\n",
    "for epoch in range(40):\n",
    "    \n",
    "#   for image,label in trainloader:\n",
    "#       image, label = image.to(device), label.to(device)\n",
    "#       optimizer.zero_grad()\n",
    "#       loss = crossent_loss(student(image), label)\n",
    "#       loss.backward()\n",
    "#       optimizer.step()\n",
    "        \n",
    "  for image,_ in unlabeledloader:\n",
    "    image = image.to(device)\n",
    "    loss = distill_loss(teacher(image),student(image))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "  metrics_dict = evaluate(student,testloader,crossent_loss)\n",
    "  val_loss = metrics_dict['val_loss']\n",
    "  if val_loss < best_loss:        \n",
    "        best_loss = val_loss\n",
    "        best_metrics = metrics_dict\n",
    "        count = 0\n",
    "  else:\n",
    "    count += 1\n",
    "  if count > patience:\n",
    "    break\n",
    "\n",
    "print('\\nBest metrics:')\n",
    "acc = best_metrics['acc']\n",
    "f1 = best_metrics['f1']\n",
    "recall = best_metrics['recall']\n",
    "precision = best_metrics['precision']\n",
    "print(f'acc:{acc:.3f} f1:{f1:.3f} precision:{precision:.3f} recall:{recall:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
